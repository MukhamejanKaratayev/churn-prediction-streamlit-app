import streamlit as st
import pandas as pd
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import MinMaxScaler
import pickle


st.set_page_config(
    page_title="Churn Prediction App",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded",
)

# global variables
df_predicted = pd.DataFrame()
uploaded_file = None

# session stare initialization
if 'df_input' not in st.session_state or uploaded_file is None:
    st.session_state['df_input'] = pd.DataFrame()

if 'df_predicted' not in st.session_state:
    st.session_state['df_predicted'] = pd.DataFrame()

# ML section start
numerical = ['tenure', 'monthlycharges', 'totalcharges']
categorical = ['gender',
'seniorcitizen',
'partner',
'dependents',
'phoneservice',
'multiplelines',
'internetservice',
'onlinesecurity',
'onlinebackup',
'deviceprotection',
'techsupport',
'streamingtv',
'streamingmovies',
'contract',
'paperlessbilling',
'paymentmethod']
le_enc_cols = ['gender', 'partner', 'dependents','paperlessbilling', 'phoneservice']
gender_map = {'male': 0, 'female': 1}
y_n_map = {'yes': 1, 'no': 0}

# logistic regression model
model_file_path = 'models/lr_model_churn_prediction.sav'
model = pickle.load(open(model_file_path, 'rb'))

# encoding model DictVectorizer
encoding_model_file_path = 'models/encoding_model.sav'
encoding_model = pickle.load(open(encoding_model_file_path, 'rb'))

@st.cache_data
def predict_churn(df_input, treshold):

    scaler = MinMaxScaler()

    df_original = df_input.copy()
    df_input[numerical] = scaler.fit_transform(df_input[numerical])

    for col in le_enc_cols:
        if col == 'gender':
            df_input[col] = df_input[col].map(gender_map)
        else:
            df_input[col] = df_input[col].map(y_n_map)

    dicts_df = df_input[categorical + numerical].to_dict(orient='records')
    X = encoding_model.transform(dicts_df)
    # X[np.isnan(X)] = 0
    y_pred = model.predict_proba(X)[:, 1]
    churn_descision = (y_pred >= treshold).astype(int)
    df_original['churn_predicted'] = churn_descision
    df_original['churn_predicted_probability'] = y_pred

    return df_original

@st.cache_data
def convert_df(df):
    # IMPORTANT: Cache the conversion to prevent computation on every rerun
    return df.to_csv(index=False).encode('utf-8')

# Sidebar section start
with st.sidebar:
    st.title('üóÇ –í–≤–æ–¥ –¥–∞–Ω–Ω—ã—Ö')
    
    tab1, tab2 = st.tabs(['üìÅ –î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞', 'üìù –í–≤–µ—Å—Ç–∏ –≤—Ä—É—á–Ω—É—é'])
    with tab1:
        uploaded_file = st.file_uploader("–í—ã–±—Ä–∞—Ç—å CSV —Ñ–∞–π–ª", type=['csv', 'xlsx'])
        if uploaded_file is not None:
            treshold = st.slider('–ü–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –æ—Ç—Ç–æ–∫–∞', 0.0, 1.0, 0.5, 0.01)
            prediction_button = st.button('–ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å', type='primary', use_container_width=True)
            st.session_state['df_input'] = pd.read_csv(uploaded_file)
            if prediction_button:
                st.session_state['df_predicted'] = predict_churn(st.session_state['df_input'], treshold)
                
            
            

# Sidebar section end

# Main section start
st.image('https://miro.medium.com/v2/resize:fit:1400/1*WqId29D5dN_8DhiYQcHa2w.png', width=400)
st.title('–ü—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤')

with st.expander("–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞"):
    st.write("""
    –í –¥–∞–Ω–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ –º—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∑–∞–¥–∞—á—É –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è –æ—Ç—Ç–æ–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤.
    –î–ª—è —ç—Ç–æ–≥–æ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç –∏–∑ –æ—Ç–∫—Ä—ã—Ç—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.
    –î–∞—Ç–∞—Å–µ—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–ª–∏–µ–Ω—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ —É—à–ª–∏ –∏–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å –≤ –∫–æ–º–ø–∞–Ω–∏–∏.
    –ù–∞—à–∞ –∑–∞–¥–∞—á–∞ - –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –æ—Ç—Ç–æ–∫ –∫–ª–∏–µ–Ω—Ç–æ–≤.
    """)

if len(st.session_state['df_input']) > 0:
    st.subheader('–î–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞')
    st.write(st.session_state['df_input'])

if len(st.session_state['df_predicted']) > 0:
    st.subheader('–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è')
    st.write(st.session_state['df_predicted'])
    res_all_csv = convert_df(st.session_state['df_predicted'])
    st.download_button(
        label="–°–∫–∞—á–∞—Ç—å –≤—Å–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è",
        data=res_all_csv,
        file_name='df-churn-predicted-all.csv',
        mime='text/csv',
    )